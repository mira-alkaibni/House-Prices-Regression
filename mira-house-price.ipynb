{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31239,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:05:09.459226Z","iopub.execute_input":"2026-01-13T07:05:09.459557Z","iopub.status.idle":"2026-01-13T07:05:09.466142Z","shell.execute_reply.started":"2026-01-13T07:05:09.459532Z","shell.execute_reply":"2026-01-13T07:05:09.464999Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\n# حفظ IDs\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n# حذف IDs\ntrain.drop(\"Id\", axis=1, inplace=True)\ntest.drop(\"Id\", axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:36.234511Z","iopub.execute_input":"2026-01-13T07:09:36.235454Z","iopub.status.idle":"2026-01-13T07:09:36.282703Z","shell.execute_reply.started":"2026-01-13T07:09:36.235419Z","shell.execute_reply":"2026-01-13T07:09:36.281668Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:39.249710Z","iopub.execute_input":"2026-01-13T07:09:39.250057Z","iopub.status.idle":"2026-01-13T07:09:39.259240Z","shell.execute_reply.started":"2026-01-13T07:09:39.250031Z","shell.execute_reply":"2026-01-13T07:09:39.257986Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"y_train = np.log1p(train['SalePrice'])\ntrain.drop(['SalePrice'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:41.397406Z","iopub.execute_input":"2026-01-13T07:09:41.397743Z","iopub.status.idle":"2026-01-13T07:09:41.405483Z","shell.execute_reply.started":"2026-01-13T07:09:41.397706Z","shell.execute_reply":"2026-01-13T07:09:41.404512Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"ntrain = train.shape[0]\nntest = test.shape[0]\nall_data = pd.concat((train, test)).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:43.101747Z","iopub.execute_input":"2026-01-13T07:09:43.102842Z","iopub.status.idle":"2026-01-13T07:09:43.117118Z","shell.execute_reply.started":"2026-01-13T07:09:43.102806Z","shell.execute_reply":"2026-01-13T07:09:43.115716Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"for col in ('PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n            'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n            'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n            'MasVnrType', 'MSSubClass'):\n    all_data[col] = all_data[col].fillna('None')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:44.329316Z","iopub.execute_input":"2026-01-13T07:09:44.330369Z","iopub.status.idle":"2026-01-13T07:09:44.350912Z","shell.execute_reply.started":"2026-01-13T07:09:44.330255Z","shell.execute_reply":"2026-01-13T07:09:44.349870Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"for col in ('GarageYrBlt', 'GarageArea', 'GarageCars',\n            'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n            'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea'):\n    all_data[col] = all_data[col].fillna(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:45.665423Z","iopub.execute_input":"2026-01-13T07:09:45.665762Z","iopub.status.idle":"2026-01-13T07:09:45.677226Z","shell.execute_reply.started":"2026-01-13T07:09:45.665719Z","shell.execute_reply":"2026-01-13T07:09:45.676029Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median())\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:46.889128Z","iopub.execute_input":"2026-01-13T07:09:46.889474Z","iopub.status.idle":"2026-01-13T07:09:46.903127Z","shell.execute_reply.started":"2026-01-13T07:09:46.889449Z","shell.execute_reply":"2026-01-13T07:09:46.902230Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"for col in ('MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st',\n            'Exterior2nd', 'SaleType', 'Functional'):\n    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n\nall_data = all_data.drop(['Utilities'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:48.293350Z","iopub.execute_input":"2026-01-13T07:09:48.293725Z","iopub.status.idle":"2026-01-13T07:09:48.313945Z","shell.execute_reply.started":"2026-01-13T07:09:48.293699Z","shell.execute_reply":"2026-01-13T07:09:48.312661Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:49.507395Z","iopub.execute_input":"2026-01-13T07:09:49.507790Z","iopub.status.idle":"2026-01-13T07:09:49.519991Z","shell.execute_reply.started":"2026-01-13T07:09:49.507768Z","shell.execute_reply":"2026-01-13T07:09:49.518572Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\nall_data['Total_sqr_footage'] = (all_data['BsmtFinSF1'] + all_data['BsmtFinSF2'] +\n                                 all_data['1stFlrSF'] + all_data['2ndFlrSF'])\nall_data['Total_Bathrooms'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) +\n                               all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\nall_data['Total_porch_sf'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] +\n                              all_data['EnclosedPorch'] + all_data['ScreenPorch'] +\n                              all_data['WoodDeckSF'])\nall_data['haspool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nall_data['has2ndfloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data['hasgarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nall_data['hasbsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nall_data['hasfireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:09:50.843457Z","iopub.execute_input":"2026-01-13T07:09:50.843830Z","iopub.status.idle":"2026-01-13T07:09:50.868311Z","shell.execute_reply.started":"2026-01-13T07:09:50.843806Z","shell.execute_reply":"2026-01-13T07:09:50.867297Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond',\n        'ExterQual', 'ExterCond', 'HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1',\n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond',\n        'YrSold', 'MoSold')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:11:25.445804Z","iopub.execute_input":"2026-01-13T07:11:25.446129Z","iopub.status.idle":"2026-01-13T07:11:25.452042Z","shell.execute_reply.started":"2026-01-13T07:11:25.446107Z","shell.execute_reply":"2026-01-13T07:11:25.450741Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"for c in cols:\n    lbl = LabelEncoder()\n    lbl.fit(list(all_data[c].values))\n    all_data[c] = lbl.transform(list(all_data[c].values))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:11:26.298271Z","iopub.execute_input":"2026-01-13T07:11:26.298737Z","iopub.status.idle":"2026-01-13T07:11:26.348771Z","shell.execute_reply.started":"2026-01-13T07:11:26.298703Z","shell.execute_reply":"2026-01-13T07:11:26.347633Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\nskewed_feats = all_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew': skewed_feats})\nskewness = skewness[abs(skewness) > 0.75]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:11:37.588716Z","iopub.execute_input":"2026-01-13T07:11:37.589052Z","iopub.status.idle":"2026-01-13T07:11:37.616163Z","shell.execute_reply.started":"2026-01-13T07:11:37.589027Z","shell.execute_reply":"2026-01-13T07:11:37.614671Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    all_data[feat] = boxcox1p(all_data[feat], lam)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:11:45.078335Z","iopub.execute_input":"2026-01-13T07:11:45.079043Z","iopub.status.idle":"2026-01-13T07:11:45.120955Z","shell.execute_reply.started":"2026-01-13T07:11:45.079004Z","shell.execute_reply":"2026-01-13T07:11:45.119743Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"all_data = pd.get_dummies(all_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:11:54.147470Z","iopub.execute_input":"2026-01-13T07:11:54.147839Z","iopub.status.idle":"2026-01-13T07:11:54.185178Z","shell.execute_reply.started":"2026-01-13T07:11:54.147813Z","shell.execute_reply":"2026-01-13T07:11:54.183546Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"train = all_data[:ntrain]\ntest = all_data[ntrain:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:11:59.990553Z","iopub.execute_input":"2026-01-13T07:11:59.990870Z","iopub.status.idle":"2026-01-13T07:11:59.996818Z","shell.execute_reply.started":"2026-01-13T07:11:59.990850Z","shell.execute_reply":"2026-01-13T07:11:59.995700Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n\ndef rmsle_cv(model):\n    rmse = np.sqrt(-cross_val_score(\n        model,\n        train.values,\n        y_train,\n        scoring=\"neg_mean_squared_error\",\n        cv=kfolds\n    ))\n    return rmse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:12:14.884686Z","iopub.execute_input":"2026-01-13T07:12:14.885015Z","iopub.status.idle":"2026-01-13T07:12:14.891509Z","shell.execute_reply.started":"2026-01-13T07:12:14.884990Z","shell.execute_reply":"2026-01-13T07:12:14.890077Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"lasso = Lasso(alpha=0.0005, random_state=1)\nridge = Ridge(alpha=10, random_state=1)\nelasticnet = ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=3)\ngbr = GradientBoostingRegressor(\n    n_estimators=3000,\n    learning_rate=0.05,\n    max_depth=4,\n    max_features='sqrt',\n    min_samples_leaf=15,\n    min_samples_split=10,\n    loss='huber',\n    random_state=5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:12:36.594380Z","iopub.execute_input":"2026-01-13T07:12:36.594738Z","iopub.status.idle":"2026-01-13T07:12:36.602425Z","shell.execute_reply.started":"2026-01-13T07:12:36.594715Z","shell.execute_reply":"2026-01-13T07:12:36.600919Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"xgb = XGBRegressor(\n    learning_rate=0.01,\n    n_estimators=3460,\n    max_depth=3,\n    min_child_weight=0,\n    gamma=0,\n    subsample=0.7,\n    colsample_bytree=0.7,\n    objective='reg:squarederror',\n    nthread=-1,\n    scale_pos_weight=1,\n    seed=27,\n    reg_alpha=0.00006\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:12:46.338262Z","iopub.execute_input":"2026-01-13T07:12:46.338574Z","iopub.status.idle":"2026-01-13T07:12:46.345787Z","shell.execute_reply.started":"2026-01-13T07:12:46.338553Z","shell.execute_reply":"2026-01-13T07:12:46.344397Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"lgb = LGBMRegressor(\n    objective='regression',\n    num_leaves=5,\n    learning_rate=0.05,\n    n_estimators=720,\n    max_bin=55,\n    bagging_fraction=0.8,\n    bagging_freq=5,\n    feature_fraction=0.2319,\n    feature_fraction_seed=9,\n    bagging_seed=9,\n    min_data_in_leaf=6,\n    min_sum_hessian_in_leaf=11\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:13:14.009642Z","iopub.execute_input":"2026-01-13T07:13:14.009983Z","iopub.status.idle":"2026-01-13T07:13:14.016479Z","shell.execute_reply.started":"2026-01-13T07:13:14.009960Z","shell.execute_reply":"2026-01-13T07:13:14.014784Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"print(\"CV RMSLE (lower is better):\")\nmodels = [(\"Lasso\", lasso), (\"Ridge\", ridge), (\"ElasticNet\", elasticnet),\n          (\"GBR\", gbr), (\"XGB\", xgb), (\"LGB\", lgb)]\nfor name, m in models:\n    score = rmsle_cv(m).mean()\n    print(f\"{name}: {score:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:13:38.695306Z","iopub.execute_input":"2026-01-13T07:13:38.695653Z","iopub.status.idle":"2026-01-13T07:17:13.758134Z","shell.execute_reply.started":"2026-01-13T07:13:38.695627Z","shell.execute_reply":"2026-01-13T07:17:13.757042Z"}},"outputs":[{"name":"stdout","text":"CV RMSLE (lower is better):\nLasso: 0.11169\nRidge: 0.11262\nElasticNet: 0.11160\nGBR: 0.11394\nXGB: 0.11176\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003343 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1593\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 182\n[LightGBM] [Info] Start training from score 12.024654\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001021 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1599\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 185\n[LightGBM] [Info] Start training from score 12.022795\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1592\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 184\n[LightGBM] [Info] Start training from score 12.027645\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1595\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 186\n[LightGBM] [Info] Start training from score 12.022592\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001031 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1596\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 186\n[LightGBM] [Info] Start training from score 12.021510\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1599\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 187\n[LightGBM] [Info] Start training from score 12.027750\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1597\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 186\n[LightGBM] [Info] Start training from score 12.032640\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001063 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1599\n[LightGBM] [Info] Number of data points in the train set: 1312, number of used features: 187\n[LightGBM] [Info] Start training from score 12.015831\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1589\n[LightGBM] [Info] Number of data points in the train set: 1313, number of used features: 181\n[LightGBM] [Info] Start training from score 12.024490\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001079 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1603\n[LightGBM] [Info] Number of data points in the train set: 1313, number of used features: 188\n[LightGBM] [Info] Start training from score 12.020247\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\nLGB: 0.11456\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"print(\"\\nTraining models...\")\nlasso.fit(train, y_train)\nridge.fit(train, y_train)\nelasticnet.fit(train, y_train)\ngbr.fit(train, y_train)\nxgb.fit(train, y_train)\nlgb.fit(train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:19:32.426866Z","iopub.execute_input":"2026-01-13T07:19:32.427229Z","iopub.status.idle":"2026-01-13T07:19:56.168689Z","shell.execute_reply.started":"2026-01-13T07:19:32.427204Z","shell.execute_reply":"2026-01-13T07:19:56.167215Z"}},"outputs":[{"name":"stdout","text":"\nTraining models...\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001168 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1614\n[LightGBM] [Info] Number of data points in the train set: 1458, number of used features: 189\n[LightGBM] [Info] Start training from score 12.024015\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n              feature_fraction=0.2319, feature_fraction_seed=9,\n              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n              objective='regression')","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n              feature_fraction=0.2319, feature_fraction_seed=9,\n              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n              objective=&#x27;regression&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n              feature_fraction=0.2319, feature_fraction_seed=9,\n              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n              objective=&#x27;regression&#x27;)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"def blended_predictions(X):\n    return ((0.1 * elasticnet.predict(X)) +\n            (0.1 * lasso.predict(X)) +\n            (0.1 * ridge.predict(X)) +\n            (0.2 * gbr.predict(X)) +\n            (0.25 * xgb.predict(X)) +\n            (0.25 * lgb.predict(X)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:20:28.363469Z","iopub.execute_input":"2026-01-13T07:20:28.363873Z","iopub.status.idle":"2026-01-13T07:20:28.372741Z","shell.execute_reply.started":"2026-01-13T07:20:28.363844Z","shell.execute_reply":"2026-01-13T07:20:28.370920Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"print(\"\\nMaking predictions...\")\nblended_pred = np.expm1(blended_predictions(test.values))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:20:37.505444Z","iopub.execute_input":"2026-01-13T07:20:37.505996Z","iopub.status.idle":"2026-01-13T07:20:37.829210Z","shell.execute_reply.started":"2026-01-13T07:20:37.505959Z","shell.execute_reply":"2026-01-13T07:20:37.827026Z"}},"outputs":[{"name":"stdout","text":"\nMaking predictions...\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = blended_pred\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:20:50.755775Z","iopub.execute_input":"2026-01-13T07:20:50.756179Z","iopub.status.idle":"2026-01-13T07:20:50.778162Z","shell.execute_reply.started":"2026-01-13T07:20:50.756153Z","shell.execute_reply":"2026-01-13T07:20:50.777157Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"print(\"\\nDone! Check submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:20:56.768512Z","iopub.execute_input":"2026-01-13T07:20:56.768878Z","iopub.status.idle":"2026-01-13T07:20:56.776164Z","shell.execute_reply.started":"2026-01-13T07:20:56.768853Z","shell.execute_reply":"2026-01-13T07:20:56.775067Z"}},"outputs":[{"name":"stdout","text":"\nDone! Check submission.csv\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"best_name, best_model = min(models, key=lambda t: rmsle_cv(t[1]).mean())\nprint(f\"Best single model by CV: {best_name} | RMSLE: {rmsle_cv(best_model).mean():.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T07:21:10.920458Z","iopub.execute_input":"2026-01-13T07:21:10.920833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}